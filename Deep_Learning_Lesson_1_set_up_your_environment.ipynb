{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jollyhrothgar/deep_learning/blob/master/Deep_Learning_Lesson_1_set_up_your_environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBtGXWJ23CP5"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "To get this working on linux with a graphics card that supports CUDA accelleration, tensorflow, etc, we have to do many annoying steps, which I have attempted to document here.\n",
    "\n",
    "## Step 0 - Start over after a system reboot resulted in everything going away.\n",
    "\n",
    "After rebooting my system, attempting to restart the docker container created errors becuase the GPU was no longer recognized by docker as a valid device. This almost certainly means drives got updated and now everything is broken.\n",
    "\n",
    "The docker stuff should all remain valid, assuming that we can get the GPU drivers fixed. Following [this guide here](https://collabnix.com/introducing-new-docker-cli-api-support-for-nvidia-gpus-under-docker-engine-19-03-0-beta-release/) for a CLI driven setup.\n",
    "\n",
    "## Step 1 - Install the latest Nvidia Drivers from the \"Proprietary Drives\" Setting in Ubuntu\n",
    "\n",
    "* Confirm its working by running\n",
    "\n",
    "```bash\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "To get an output such as:\n",
    "\n",
    "```\n",
    "Mon Aug 31 16:41:35 2020       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n",
    "|  0%   32C    P8    14W / 250W |    510MiB / 11176MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                       GPU Memory |\n",
    "|  GPU       PID   Type   Process name                             Usage      |\n",
    "|=============================================================================|\n",
    "|    0      1359      G   /usr/lib/xorg/Xorg                            24MiB |\n",
    "|    0      1496      G   /usr/bin/gnome-shell                          50MiB |\n",
    "|    0      2406      G   /usr/lib/xorg/Xorg                           145MiB |\n",
    "|    0      2544      G   /usr/bin/gnome-shell                         152MiB |\n",
    "|    0      4018      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files   133MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "\n",
    "```\n",
    "## Step 2 - Set up docker, make sure your local user is added to the docker group.\n",
    "\n",
    "## Step 3 - Get the NVIDIA docker container from tensorflow\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/install/docker) has documentation for accomplishing this, but the quick version is:\n",
    "\n",
    "```bash\n",
    "docker pull tensorflow/tensorflow:latest-gpu-jupyter\n",
    "```\n",
    "\n",
    "## Step 4 - Prepare / persist shit between runs so you can connect to colab\n",
    "\n",
    "\n",
    "This gets run once:\n",
    "```bash\n",
    "docker run -ti --gpus all --rm -u $(id -u):$(id -g) -v \"${HOME}/.config/jupyter:/.jupyter\" tensorflow/tensorflow:latest-gpu-jupyter bash -c \"source /etc/bash.bashrc && jupyter serverextension enable --py jupyter_http_over_ws\"\n",
    "```\n",
    "\n",
    "## Step 5 - Run the docker container with the config:\n",
    "\n",
    "```bash\n",
    "docker run -it -u $(id -u):$(id -g) --gpus all -p 8888:8888 -v \"${HOME}/.config/jupyter:/.jupyter\" -v \"${HOME}/workspace:/tf\" tensorflow/tensorflow:latest-gpu-jupyter bash -c \"source /etc/bash.bashrc && jupyter notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --NotebookApp.allow_origin='https://colab.research.google.com'\"\n",
    "```\n",
    "\n",
    "Obviously, you have to have your directory structure set up - for example, directorys like `${HOME}/workspace` and `${HOME}/.config/jupyter` have to exist.\n",
    "\n",
    "\n",
    "## Step 6 Connect Local Runtime to Colab\n",
    "\n",
    "Go to colab, and connect to a local runtime, pasting the string that looks like this:\n",
    "\n",
    "`http://127.0.0.1:8888/?token=<long alphanumeric token>` into place for the backend URL, but replace `127.0.0.1` with `localhost`, since you tunneled the port earlier when you wrote `-p 8888:8888` in your docker run command.\n",
    "\n",
    "## Step 7 - Make an executable to run your docker setup so you don't have to remember this shit.\n",
    "\n",
    "## Step 8 - Run these commands with your local runtime connected.\n",
    "\n",
    "You should see something that indicates your GPU is connected like:\n",
    "\n",
    "`[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]`\n",
    "\n",
    "## Step 9 - Write Down the Useful Links you Found\n",
    "\n",
    "* https://jupyter-docker-stacks.readthedocs.io/en/latest/using/running.html\n",
    "* https://docs.docker.com/engine/reference/run/\n",
    "* https://stackoverflow.com/questions/61024722/how-to-use-google-colab-with-a-local-tensorflow-jupyter-server-using-powershell\n",
    "* https://github.com/tensorflow/tensorflow/issues/25247#issuecomment-459644861\n",
    "* https://stackoverflow.com/questions/58191215/how-to-add-python-libraries-to-docker-image\n",
    "* https://research.google.com/colaboratory/local-runtimes.html\n",
    "\n",
    "## Step 10: Vomit From Exhaustion\n",
    "\n",
    "## Step 11: Setup Additional Dependencies\n",
    "\n",
    "You might want to add stuff like pandas, matplotlib, seaborn, etc, to create a more full-featured analysis environment. You can do so by building a dockerfile based on another docker container.\n",
    "\n",
    "You can have a file such as this:\n",
    "\n",
    "```\n",
    "# requirements.txt\n",
    "\n",
    "pandas\n",
    "sklearn\n",
    "matplotlib\n",
    "seaborn\n",
    "```\n",
    "\n",
    "And then build your own docker image based on a tensorflow image that works:\n",
    "\n",
    "```\n",
    "# Dockerfile\n",
    "\n",
    "FROM tensorflow/tensorflow:latest-gpu-jupyter\n",
    "\n",
    "RUN python -m pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1_ob8E--4Xxb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kDcv1Gct5LL4",
    "outputId": "a178344c-19b1-48d4-bf16-81ba6821defc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MjHd5_ks8Y8r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNq+Kye9BUV62kuqDynV42M",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Deep Learning Lesson 1 - set up your environment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
